{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebddde10",
   "metadata": {},
   "source": [
    "# Task 2 — Deep Learning with TensorFlow \n",
    "### Dataset: MNIST Handwritten Digits\n",
    "#### Objectives:\n",
    "- Build and train a CNN to classify handwritten digits (0–9).\n",
    "- Achieve >95% accuracy.\n",
    "- Visualize model predictions on 5 test samples.\n",
    "- Save trained model for later deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997c42f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully! TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 1 Import Dependencies\n",
    "# ============================\n",
    "# Import TensorFlow library for deep learning operations\n",
    "import tensorflow as tf\n",
    "# Import specific modules from TensorFlow Keras for building neural network layers and models\n",
    "from tensorflow.keras import layers, models  # type: ignore\n",
    "# Import ImageDataGenerator for data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # type: ignore\n",
    "# Import matplotlib for plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# Import NumPy for numerical operations and array handling\n",
    "import numpy as np\n",
    "# Print confirmation of successful imports and TensorFlow version\n",
    "print('Libraries imported successfully! TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4257754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (60000, 28, 28, 1)  Test set: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 2 Load and Preprocess Data\n",
    "# ============================\n",
    "# Load the MNIST dataset from Keras datasets\n",
    "# MNIST contains 70,000 handwritten digit images (28x28 pixels)\n",
    "# x_train, y_train: training images and labels\n",
    "# x_test, y_test: test images and labels\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values from 0-255 to 0-1 for better neural network performance\n",
    "# This also converts the data to float32 implicitly\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshape images to include a channel dimension for CNN input\n",
    "# Original shape: (num_samples, 28, 28) -> New shape: (num_samples, 28, 28, 1)\n",
    "# CNNs expect 4D tensors: (batch_size, height, width, channels)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Print the shapes of training and test sets to verify preprocessing\n",
    "print('Train set:', x_train.shape, ' Test set:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f832a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2.5 Data Augmentation for Robustness\n",
    "# ============================\n",
    "# To improve model robustness against varied handwriting styles,\n",
    "# apply data augmentation techniques like rotation, shift, and zoom.\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,      # Rotate images by up to 10 degrees\n",
    "    width_shift_range=0.1,  # Shift horizontally by up to 10%\n",
    "    height_shift_range=0.1, # Shift vertically by up to 10%\n",
    "    zoom_range=0.1          # Zoom in/out by up to 10%\n",
    ")\n",
    "# Fit the generator on training data to learn stats\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68cd03f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,930</span> (476.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,930\u001b[0m (476.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# 3 Build CNN Architecture\n",
    "# ============================\n",
    "# Create a Sequential model - layers are stacked sequentially\n",
    "model = models.Sequential([\n",
    "    # First convolutional layer: 32 filters of 3x3, ReLU activation\n",
    "    # input_shape specifies the shape of input images (28x28x1)\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # First max pooling layer: 2x2 pool size reduces spatial dimensions by half\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Second convolutional layer: 64 filters of 3x3, ReLU activation\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Second max pooling layer: 2x2 pool size further reduces dimensions\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Flatten layer: converts 2D feature maps to 1D vector for dense layers\n",
    "    layers.Flatten(),\n",
    "    # First dense layer: 64 neurons with ReLU activation for feature processing\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    # Dropout layer: randomly set 50% of inputs to zero during training to prevent overfitting\n",
    "    layers.Dropout(0.5),\n",
    "    # Output layer: 10 neurons (one for each digit 0-9) with softmax activation\n",
    "    # Softmax converts outputs to probabilities that sum to 1\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Display a summary of the model architecture including layer details and parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f16446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 122ms/step - accuracy: 0.7645 - loss: 0.7255 - val_accuracy: 0.9782 - val_loss: 0.0737\n",
      "Epoch 2/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.9028 - loss: 0.3163 - val_accuracy: 0.9819 - val_loss: 0.0538\n",
      "Epoch 3/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 94ms/step - accuracy: 0.9269 - loss: 0.2434 - val_accuracy: 0.9861 - val_loss: 0.0394\n",
      "Epoch 4/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 101ms/step - accuracy: 0.9397 - loss: 0.2009 - val_accuracy: 0.9891 - val_loss: 0.0321\n",
      "Epoch 5/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 79ms/step - accuracy: 0.9492 - loss: 0.1742 - val_accuracy: 0.9907 - val_loss: 0.0266\n",
      "Epoch 6/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 82ms/step - accuracy: 0.9549 - loss: 0.1526 - val_accuracy: 0.9908 - val_loss: 0.0271\n",
      "Epoch 7/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - accuracy: 0.9587 - loss: 0.1373 - val_accuracy: 0.9896 - val_loss: 0.0282\n",
      "Epoch 8/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 131ms/step - accuracy: 0.9619 - loss: 0.1300 - val_accuracy: 0.9917 - val_loss: 0.0234\n",
      "Epoch 9/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 93ms/step - accuracy: 0.9631 - loss: 0.1247 - val_accuracy: 0.9909 - val_loss: 0.0261\n",
      "Epoch 10/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - accuracy: 0.9681 - loss: 0.1108 - val_accuracy: 0.9895 - val_loss: 0.0287\n",
      "Epoch 11/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 81ms/step - accuracy: 0.9678 - loss: 0.1098 - val_accuracy: 0.9930 - val_loss: 0.0215\n",
      "Epoch 12/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 92ms/step - accuracy: 0.9702 - loss: 0.1008 - val_accuracy: 0.9918 - val_loss: 0.0242\n",
      "Epoch 13/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - accuracy: 0.9715 - loss: 0.0987 - val_accuracy: 0.9924 - val_loss: 0.0246\n",
      "Epoch 14/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 106ms/step - accuracy: 0.9714 - loss: 0.0975 - val_accuracy: 0.9931 - val_loss: 0.0213\n",
      "Epoch 15/15\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - accuracy: 0.9740 - loss: 0.0896 - val_accuracy: 0.9933 - val_loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 4 Compile and Train the Model\n",
    "# ============================\n",
    "# Compile the model with:\n",
    "# - Adam optimizer: adaptive learning rate optimization algorithm\n",
    "# - Sparse categorical crossentropy: suitable for integer labels (0-9) without one-hot encoding\n",
    "# - Accuracy metric: tracks percentage of correctly predicted labels\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using data augmentation for more robust performance\n",
    "# - Use datagen.flow to generate augmented batches on-the-fly\n",
    "# - epochs increased to 15 for better convergence with augmentation\n",
    "# - batch_size=128: process 128 samples at a time\n",
    "# - validation_data: use fixed test set for validation (no augmentation)\n",
    "# - verbose=1: show progress bar\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=15, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Alternative pure augmentation (if pref train/test split):\n",
    "# history = model.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=15, validation_split=0.1, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc9bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 99.33%\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 5 Evaluate Model Accuracy\n",
    "# ============================\n",
    "# Evaluate the trained model on the test set (unseen data)\n",
    "# Returns loss value and computed metrics (accuracy in this case)\n",
    "# verbose=0: silent evaluation, no progress bar shown\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print the test accuracy as a percentage with 2 decimal places\n",
    "print(f'\\nTest Accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a26034d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../bonus/mnist_cnn_improved_model.h5\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6 Save Model for Deployment\n",
    "# ============================\n",
    "# Save the trained model to disk in HDF5 format\n",
    "# This includes the model architecture, weights, and compilation configuration\n",
    "# Can be loaded later for inference or further training\n",
    "model.save('../../bonus/mnist_cnn_improved_model.h5')\n",
    "\n",
    "# Confirm that the model has been saved successfully\n",
    "print('Model saved to ../../bonus/mnist_cnn_improved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fd2d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# 7 Visualize Predictions on 5 Random Images\n",
    "# ============================\n",
    "# Select 5 random indices from the test set without replacement\n",
    "indices = np.random.choice(len(x_test), 5, replace=False)\n",
    "\n",
    "# Extract the corresponding images and true labels\n",
    "images = x_test[indices]\n",
    "labels = y_test[indices]\n",
    "\n",
    "# Generate predictions for the selected images using the trained model\n",
    "# Use argmax to convert softmax probabilities to class predictions (0-9)\n",
    "predictions = np.argmax(model.predict(images), axis=1)\n",
    "\n",
    "# Create a 1x5 subplot figure for visualization\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i, idx in enumerate(indices):\n",
    "    # Create subplot for each image\n",
    "    plt.subplot(1, 5, i+1)\n",
    "\n",
    "    # Display the image in grayscale\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "\n",
    "    # Set title showing true label and predicted label\n",
    "    plt.title(f'True: {labels[i]}\\nPred: {predictions[i]}')\n",
    "\n",
    "    # Turn off axis labels for cleaner visualization\n",
    "    plt.axis('off')\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
